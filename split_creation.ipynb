{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Preprocessed/TimeFeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        station_id  day  month  year  hour  AM_PM  original_index\n",
      "828           1001   23      4     0    15      1             828\n",
      "1919          1001   24      6     0     6      0            1919\n",
      "473           1001    6      4     0    11      0             473\n",
      "1533          1001   24      5     0    21      1            1533\n",
      "4257          1001   27      9     0     4      0            4257\n",
      "...            ...  ...    ...   ...   ...    ...             ...\n",
      "168213        1036    7     11     0     7      0          168213\n",
      "168598        1036   14     12     0     7      0          168598\n",
      "168486        1036   18     11     0    19      1          168486\n",
      "169268        1036   11      1     1    12      1          169268\n",
      "169393        1036   16      1     1    19      1          169393\n",
      "\n",
      "[118957 rows x 7 columns]\n",
      "        station_id  day  month  year  hour  AM_PM  original_index\n",
      "10745         1002   15      9     0    16      1           10745\n",
      "124389        1019   29      7     0     0      0          124389\n",
      "10264         1002   28      8     0    23      1           10264\n",
      "47880         1008    9      4     0     6      0           47880\n",
      "93269         1014   12     12     0     6      0           93269\n",
      "...            ...  ...    ...   ...   ...    ...             ...\n",
      "3222          1001   18      8     0    21      1            3222\n",
      "73972         1011   22      1     1    20      1           73972\n",
      "42284         1007    1      6     0     9      0           42284\n",
      "137665        1021   17      9     0    11      0          137665\n",
      "106785        1016   12     12     0     9      0          106785\n",
      "\n",
      "[25490 rows x 7 columns]\n",
      "        station_id  day  month  year  hour  AM_PM  original_index\n",
      "3             1001    9      2     0     2      0               3\n",
      "4             1001    9      2     0     3      0               4\n",
      "9             1001    9      2     0     8      0               9\n",
      "21            1001    9      2     0    20      1              21\n",
      "27            1001   10      2     0     3      0              27\n",
      "...            ...  ...    ...   ...   ...    ...             ...\n",
      "169915        1036    8      2     1     3      0          169915\n",
      "169918        1036    8      2     1     6      0          169918\n",
      "169919        1036    8      2     1     7      0          169919\n",
      "169932        1036    8      2     1    20      1          169932\n",
      "169935        1036    8      2     1    23      1          169935\n",
      "\n",
      "[25489 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/3k_51w_j5yd8v5cpqy1brfqr0000gn/T/ipykernel_63264/3946124605.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_train = df.groupby('station_id', group_keys=False).apply(lambda x: x.sample(frac=0.7, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "df_train = df.groupby('station_id', group_keys=False).apply(lambda x: x.sample(frac=0.7, random_state=42))\n",
    "print(df_train)\n",
    "\n",
    "df_remaining = df.drop(df_train.index)\n",
    "df_val = df_remaining.sample(frac=0.5, random_state=42)\n",
    "print(df_val)\n",
    "\n",
    "df_test = df_remaining.drop(df_val.index)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('Data/Preprocessed/Features.csv')\n",
    "df_positionfeatures = pd.read_csv('Data/Preprocessed/PositionFeatures.csv')\n",
    "df_timefeatures = pd.read_csv('Data/Preprocessed/TimeFeatures.csv')\n",
    "df_values = pd.read_csv('Data/Preprocessed/Values.csv')\n",
    "\n",
    "df_train_features = df_features.loc[df_train.index]\n",
    "df_train_positionfeatures = df_positionfeatures.loc[df_train.index]\n",
    "df_train_timefeatures = df_timefeatures.loc[df_train.index]\n",
    "df_train_values = df_values.loc[df_train.index]\n",
    "\n",
    "df_train_features.to_csv('Data/Split1/Train/Features.csv', index=False)\n",
    "df_train_positionfeatures.to_csv('Data/Split1/Train/PositionFeatures.csv', index=False)\n",
    "df_train_timefeatures.to_csv('Data/Split1/Train/TimeFeatures.csv', index=False)\n",
    "df_train_values.to_csv('Data/Split1/Train/Values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_features = df_features.loc[df_val.index]\n",
    "df_val_positionfeatures = df_positionfeatures.loc[df_val.index]\n",
    "df_val_timefeatures = df_timefeatures.loc[df_val.index]\n",
    "df_val_values = df_values.loc[df_val.index]\n",
    "\n",
    "df_val_features.to_csv('Data/Split1/Val/Features.csv', index=False)\n",
    "df_val_positionfeatures.to_csv('Data/Split1/Val/PositionFeatures.csv', index=False)\n",
    "df_val_timefeatures.to_csv('Data/Split1/Val/TimeFeatures.csv', index=False)\n",
    "df_val_values.to_csv('Data/Split1/Val/Values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_features = df_features.loc[df_test.index]\n",
    "df_test_positionfeatures = df_positionfeatures.loc[df_test.index]\n",
    "df_test_timefeatures = df_timefeatures.loc[df_test.index]\n",
    "df_test_values = df_values.loc[df_test.index]\n",
    "\n",
    "df_test_features.to_csv('Data/Split1/Test/Features.csv', index=False)\n",
    "df_test_positionfeatures.to_csv('Data/Split1/Test/PositionFeatures.csv', index=False)\n",
    "df_test_timefeatures.to_csv('Data/Split1/Test/TimeFeatures.csv', index=False)\n",
    "df_test_values.to_csv('Data/Split1/Test/Values.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
