{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([118957, 256])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather data from csv files\n",
    "position_data = pd.read_csv(\"Data/Split1/Train/PositionFeatures.csv\")\n",
    "time_data = pd.read_csv(\"Data/Split1/Train/TimeFeatures.csv\")\n",
    "numerical_data = pd.read_csv(\"Data/Split1/Train/Features.csv\")\n",
    "\n",
    "# spherical position embedding\n",
    "def encode_position(latitude, longitude):\n",
    "    lat_rad = math.radians(latitude)\n",
    "    lon_rad = math.radians(longitude)\n",
    "    x = math.cos(lat_rad) * math.cos(lon_rad)\n",
    "    y = math.cos(lat_rad) * math.sin(lon_rad)\n",
    "    z = math.sin(lat_rad)\n",
    "    return x, y, z\n",
    "\n",
    "# extract features from data\n",
    "position_features = position_data.apply(lambda row: encode_position(row[\"latitude\"], row[\"longitude\"]), axis=1)\n",
    "position_features = pd.DataFrame(position_features.tolist(), columns=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "time_features = pd.DataFrame()\n",
    "time_features[\"month_sin\"] = np.sin(2 * np.pi * time_data[\"month\"] / 12)\n",
    "time_features[\"month_cos\"] = np.cos(2 * np.pi * time_data[\"month\"] / 12)\n",
    "time_features[\"day_sin\"] = np.sin(2 * np.pi * time_data[\"day\"] / 31)\n",
    "time_features[\"day_cos\"] = np.cos(2 * np.pi * time_data[\"day\"] / 31)\n",
    "time_features[\"hour_sin\"] = np.sin(2 * np.pi * time_data[\"hour\"] / 24)\n",
    "time_features[\"hour_cos\"] = np.cos(2 * np.pi * time_data[\"hour\"] / 24)\n",
    "time_features['year'] = time_data['year']\n",
    "time_features['AM_PM'] = time_data['AM_PM']\n",
    "\n",
    "numerical_features = numerical_data.drop(columns=['station_id'])\n",
    "\n",
    "\n",
    "# create embeddings using a linear layer\n",
    "position_embedding_layer = nn.Linear(position_features.shape[1], 256)\n",
    "position_embedding = position_embedding_layer(torch.tensor(position_features.values, dtype=torch.float32))\n",
    "\n",
    "time_embedding_layer = nn.Linear(time_features.shape[1], 256)\n",
    "time_embedding = time_embedding_layer(torch.tensor(time_features.values, dtype=torch.float32))\n",
    "\n",
    "numerical_embedding_layer = nn.Linear(numerical_features.shape[1], 256)\n",
    "numerical_embedding = numerical_embedding_layer(torch.tensor(numerical_features.values, dtype=torch.float32))\n",
    "\n",
    "# add embeddings together to get input\n",
    "X_train = position_embedding + time_embedding + numerical_embedding\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([118957, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather output values\n",
    "output_values = pd.read_csv(\"Data/Split1/Train/Values.csv\")\n",
    "\n",
    "# extract output values\n",
    "output_values = output_values.drop(columns=['station_id'])\n",
    "\n",
    "# convert to tensor\n",
    "y_train = torch.tensor(output_values.values, dtype=torch.float32)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatiotemporalEnconder(nn.Module):\n",
    "    def __init__(self, model_dim):\n",
    "        self.model_dim = model_dim\n",
    "        self.position_embedding_layer = nn.Linear(3, model_dim)\n",
    "        self.time_embedding_layer = nn.Linear(8, model_dim)\n",
    "        self.numerical_embedding_layer = nn.Linear(7, model_dim)\n",
    "\n",
    "    def encode_coordinates(latitude, longitude):\n",
    "        lat_rad = math.radians(latitude)\n",
    "        lon_rad = math.radians(longitude)\n",
    "        x = math.cos(lat_rad) * math.cos(lon_rad)\n",
    "        y = math.cos(lat_rad) * math.sin(lon_rad)\n",
    "        z = math.sin(lat_rad)\n",
    "        return x, y, z\n",
    "\n",
    "    def encode_time(month, day, hour, year, AM_PM):\n",
    "        month_sin = np.sin(2 * np.pi * month / 12)\n",
    "        month_cos = np.cos(2 * np.pi * month / 12)\n",
    "        day_sin = np.sin(2 * np.pi * day / 31)\n",
    "        day_cos = np.cos(2 * np.pi * day / 31)\n",
    "        hour_sin = np.sin(2 * np.pi * hour / 24)\n",
    "        hour_cos = np.cos(2 * np.pi * hour / 24)\n",
    "        return month_sin, month_cos, day_sin, day_cos, hour_sin, hour_cos, year, AM_PM\n",
    "\n",
    "    def forward(self, X):\n",
    "        if 'longitude' in X.columns and 'latitude' in X.columns:\n",
    "            position_embedding = self.position_embedding_layer(encode_coordinates(X[['latitude']], X[['longitude']]))\n",
    "        else:\n",
    "            raise ValueError(\"Input data must contain 'latitude' and 'longitude' columns\")\n",
    "    \n",
    "        if 'month' in X.columns and 'day' in X.columns and 'hour' in X.columns and 'year' in X.columns and 'AM_PM' in X.columns:\n",
    "            time_embedding = self.time_embedding_layer(encode_time(X[['month']], X[['day']], X[['hour']], X[['year']], X[['AM_PM']]))\n",
    "        else:\n",
    "            raise ValueError(\"Input data must contain 'month', 'day', 'hour', 'year', and 'AM_PM' columns\")\n",
    "        \n",
    "        X = X.drop(columns=['latitude', 'longitude', 'month', 'day', 'hour', 'year', 'AM_PM'])\n",
    "        if X.shape[1] == 7:\n",
    "            numerical_embedding = self.numerical_embedding_layer(X)\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect Numerical Features\")\n",
    "        \n",
    "        return position_embedding + time_embedding + numerical_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, output_dim, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        # define model dimensions\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = model_dim // num_heads\n",
    "\n",
    "        # define query, key, and value weight matrices which will be trained\n",
    "        self.W_Q = nn.Linear(input_dim, model_dim)\n",
    "        self.W_K = nn.Linear(input_dim, model_dim)\n",
    "        self.W_V = nn.Linear(input_dim, model_dim)\n",
    "\n",
    "        # define output weight matrix which will be trained\n",
    "        self.W_O = nn.Linear(model_dim, model_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        batch_size, input_dim = X.shape\n",
    "\n",
    "        Q = self.W_Q(X).view(batch_size, self.num_heads, self.head_dim)\n",
    "        K = self.W_K(X).view(batch_size, self.num_heads, self.head_dim)\n",
    "        V = self.W_V(X).view(batch_size, self.num_heads, self.head_dim)\n",
    "\n",
    "        attention_scores = torch.bmm(Q, K.transpose(1, 2)) / math.sqrt(self.head_dim)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        attention_output = torch.bmm(attention_weights, V).view(batch_size, -1)\n",
    "\n",
    "        output = self.W_O(attention_output)\n",
    "\n",
    "        return self.final_layer(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, model_dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.model_dim=model_dim\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(model_dim))\n",
    "        self.beta =  nn.Parameter(torch.zeros(model_dim))\n",
    "\n",
    "    def forward(self, X):\n",
    "        dims = [-(i + 1) for i in range(len(self.model_dim))]\n",
    "        mean = X.mean(dim=dims, keepdim=True)\n",
    "        var = ((X - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        y = (X - mean) / std\n",
    "        out = self.gamma * y + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, model_dim, hidden, drop_prob):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(model_dim, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, model_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, model_dim, ffn_hidden, num_heads, drop_prob):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.attention = MultiHeadAttention(model_dim=model_dim, num_heads=num_heads)\n",
    "        self.norm1 = LayerNormalization(model_dim=model_dim)\n",
    "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
    "        self.ffn = PositionwiseFeedForward(model_dim=model_dim, hidden=ffn_hidden, drop_prob=drop_prob)\n",
    "        self.norm2 = LayerNormalization(model_dim=model_dim)\n",
    "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x, self_attention_mask):\n",
    "        residual_x = x.clone()\n",
    "        x = self.attention(x, mask=self_attention_mask)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.norm1(x + residual_x)\n",
    "        residual_x = x.clone()\n",
    "        x = self.ffn(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.norm2(x + residual_x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, model_dim, num_heads, num_layers, feedforward_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Module(SpatiotemporalEnconder(model_dim))\n",
    "\n",
    "        self.layers = nn.ModuleList([MultiHeadAttention(model_dim, model_dim, model_dim, num_heads) for _ in range(num_layers)])\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(model_dim, feedforward_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feedforward_dim, model_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.encoder(X)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "\n",
    "        X = self.feedforward(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure X_train and output_values are PyTorch tensors with requires_grad=False\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Handle NaN values in X_train and output_values\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure X_train and output_values are PyTorch tensors with requires_grad=False\n",
    "X_train = X_train.clone().detach().requires_grad_(False)\n",
    "y_train = y_train.clone().detach().requires_grad_(False)\n",
    "\n",
    "# Handle NaN values in X_train and output_values\n",
    "X_train[torch.isnan(X_train)] = 0 # 0 nans\n",
    "y_train[torch.isnan(y_train)] = 0 # 1395 nans\n",
    "\n",
    "# Define model, loss function, and optimizer\n",
    "batch_size = 32\n",
    "num_heads = 8\n",
    "input_dim = X_train.shape[1]\n",
    "model_dim = 512\n",
    "output_dim = 1\n",
    "\n",
    "multi_head_attention = MultiHeadAttention(input_dim, model_dim, output_dim, num_heads)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(multi_head_attention.parameters(), lr=0.001)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        X_batch = X_train[i:i+batch_size]\n",
    "        y_batch = y_train[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = multi_head_attention(X_batch)\n",
    "\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
